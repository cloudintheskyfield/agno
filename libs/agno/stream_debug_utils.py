"""
æµå¼å“åº”è°ƒè¯•å·¥å…·
ç”¨äºæ‰“å°å’Œåˆ†ææµå¼å“åº”çš„ chunk å†…å®¹
"""

import json
import time
from typing import Any, Optional

class StreamDebugger:
    """æµå¼å“åº”è°ƒè¯•å™¨"""
    
    def __init__(self, enabled: bool = True, verbose: bool = False):
        self.enabled = enabled
        self.verbose = verbose
        self.chunk_count = 0
        self.total_content_length = 0
        self.start_time = None
        
    def start_stream(self, model_name: str = "Unknown"):
        """å¼€å§‹æµå¼å“åº”è°ƒè¯•"""
        if not self.enabled:
            return
            
        self.chunk_count = 0
        self.total_content_length = 0
        self.start_time = time.time()
        
        print(f"\nğŸš€ å¼€å§‹æµå¼å“åº” [{model_name}] - {time.strftime('%H:%M:%S')}")
        print("=" * 60)
    
    def log_chunk(self, response_delta: Any, chunk_index: Optional[int] = None):
        """è®°å½•å•ä¸ª chunk"""
        if not self.enabled:
            return
            
        self.chunk_count += 1
        current_chunk = chunk_index or self.chunk_count
        
        # æå–å†…å®¹
        content = self._extract_content(response_delta)
        
        if content:
            self.total_content_length += len(content)
            
            # åŸºç¡€ä¿¡æ¯
            print(f"ğŸ“¦ Chunk #{current_chunk:03d} | é•¿åº¦: {len(content):3d} | ç´¯è®¡: {self.total_content_length:4d}")
            
            # å†…å®¹é¢„è§ˆ
            if self.verbose:
                # è¯¦ç»†æ¨¡å¼ï¼šæ˜¾ç¤ºå®Œæ•´å†…å®¹å’Œç»“æ„
                print(f"   å†…å®¹: {repr(content)}")
                print(f"   ç±»å‹: {type(response_delta).__name__}")
                
                # æ˜¾ç¤ºå“åº”å¯¹è±¡çš„å…¶ä»–å±æ€§
                if hasattr(response_delta, '__dict__'):
                    attrs = {k: v for k, v in response_delta.__dict__.items() 
                            if not k.startswith('_') and v is not None}
                    if attrs:
                        print(f"   å±æ€§: {json.dumps(attrs, default=str, ensure_ascii=False)[:100]}...")
            else:
                # ç®€æ´æ¨¡å¼ï¼šåªæ˜¾ç¤ºå†…å®¹é¢„è§ˆ
                preview = content.replace('\n', '\\n').replace('\r', '\\r')
                if len(preview) > 50:
                    preview = preview[:47] + "..."
                print(f"   å†…å®¹: {preview}")
            
            # ç‰¹æ®Šå†…å®¹æ ‡è®°
            if '\n' in content:
                print(f"   ğŸ”„ åŒ…å«æ¢è¡Œç¬¦")
            if any(char in content for char in ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?']):
                print(f"   ğŸ“ åŒ…å«å¥å­ç»“æŸç¬¦")
                
        else:
            # æ²¡æœ‰å†…å®¹çš„ chunkï¼ˆå¯èƒ½æ˜¯å…ƒæ•°æ®æˆ–æ§åˆ¶ä¿¡æ¯ï¼‰
            print(f"ğŸ“¦ Chunk #{current_chunk:03d} | æ— å†…å®¹ | ç±»å‹: {type(response_delta).__name__}")
            
            if self.verbose and hasattr(response_delta, '__dict__'):
                attrs = {k: v for k, v in response_delta.__dict__.items() 
                        if not k.startswith('_') and v is not None}
                if attrs:
                    print(f"   å…ƒæ•°æ®: {json.dumps(attrs, default=str, ensure_ascii=False)[:100]}...")
        
        print(flush=True)
    
    def end_stream(self):
        """ç»“æŸæµå¼å“åº”è°ƒè¯•"""
        if not self.enabled or self.start_time is None:
            return
            
        duration = time.time() - self.start_time
        
        print("=" * 60)
        print(f"âœ… æµå¼å“åº”å®Œæˆ - {time.strftime('%H:%M:%S')}")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   â€¢ æ€» chunk æ•°: {self.chunk_count}")
        print(f"   â€¢ æ€»å†…å®¹é•¿åº¦: {self.total_content_length} å­—ç¬¦")
        print(f"   â€¢ è€—æ—¶: {duration:.2f} ç§’")
        if self.chunk_count > 0:
            print(f"   â€¢ å¹³å‡ chunk å¤§å°: {self.total_content_length / self.chunk_count:.1f} å­—ç¬¦")
            print(f"   â€¢ å¹³å‡ chunk é—´éš”: {duration / self.chunk_count * 1000:.1f} æ¯«ç§’")
        print()
    
    def _extract_content(self, response_delta: Any) -> str:
        """ä»å“åº”å¯¹è±¡ä¸­æå–å†…å®¹"""
        # å°è¯•å¤šç§å¯èƒ½çš„å†…å®¹å±æ€§
        content_attrs = [
            'content',
            'text', 
            'message',
            'data'
        ]
        
        for attr in content_attrs:
            if hasattr(response_delta, attr):
                value = getattr(response_delta, attr)
                if isinstance(value, str) and value:
                    return value
        
        # å°è¯• delta ç»“æ„
        if hasattr(response_delta, 'delta'):
            delta = response_delta.delta
            for attr in content_attrs:
                if hasattr(delta, attr):
                    value = getattr(delta, attr)
                    if isinstance(value, str) and value:
                        return value
        
        # å°è¯• choices ç»“æ„ï¼ˆOpenAI æ ¼å¼ï¼‰
        if hasattr(response_delta, 'choices') and response_delta.choices:
            choice = response_delta.choices[0]
            if hasattr(choice, 'delta') and hasattr(choice.delta, 'content'):
                content = choice.delta.content
                if isinstance(content, str) and content:
                    return content
        
        return ""

# å…¨å±€è°ƒè¯•å™¨å®ä¾‹
stream_debugger = StreamDebugger(enabled=True, verbose=False)

def enable_stream_debug(verbose: bool = False):
    """å¯ç”¨æµå¼å“åº”è°ƒè¯•"""
    global stream_debugger
    stream_debugger.enabled = True
    stream_debugger.verbose = verbose
    print("âœ… æµå¼å“åº”è°ƒè¯•å·²å¯ç”¨" + (" (è¯¦ç»†æ¨¡å¼)" if verbose else " (ç®€æ´æ¨¡å¼)"))

def disable_stream_debug():
    """ç¦ç”¨æµå¼å“åº”è°ƒè¯•"""
    global stream_debugger
    stream_debugger.enabled = False
    print("âŒ æµå¼å“åº”è°ƒè¯•å·²ç¦ç”¨")

def log_stream_chunk(response_delta: Any, model_name: str = "Unknown", chunk_index: Optional[int] = None):
    """è®°å½•æµå¼å“åº” chunkï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    global stream_debugger
    
    # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ª chunkï¼Œè‡ªåŠ¨å¼€å§‹è°ƒè¯•
    if stream_debugger.chunk_count == 0:
        stream_debugger.start_stream(model_name)
    
    stream_debugger.log_chunk(response_delta, chunk_index)

def finish_stream_debug():
    """å®Œæˆæµå¼å“åº”è°ƒè¯•ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    global stream_debugger
    stream_debugger.end_stream()
