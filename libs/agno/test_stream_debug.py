"""
æµ‹è¯•æµå¼è¾“å‡ºè°ƒè¯•åŠŸèƒ½
"""

from agno.agent import Agent
from agno.models.vllm import VLLM
from agno.tools.hackernews import HackerNewsTools
from stream_debug_utils import enable_stream_debug, disable_stream_debug

def test_stream_debug():
    """æµ‹è¯•æµå¼è¾“å‡ºè°ƒè¯•åŠŸèƒ½"""
    
    print("ğŸ§ª æµ‹è¯•æµå¼è¾“å‡ºè°ƒè¯•åŠŸèƒ½")
    print("=" * 50)
    
    # å¯ç”¨è¯¦ç»†è°ƒè¯•æ¨¡å¼
    enable_stream_debug(verbose=True)
    
    # åˆ›å»ºæ¨¡å‹å’Œ Agent
    model = VLLM(
        id='Qwen3-Omni-Thinking',
        base_url='http://223.109.239.14:10026/v1/',
        max_tokens=32768,
        temperature=1
    )
    
    agent = Agent(
        model=model,
        tools=[HackerNewsTools()],
        tool_choice="none",
        markdown=True,
    )
    
    # æµ‹è¯•æµå¼å“åº”
    print("\nğŸš€ å¼€å§‹æµ‹è¯•æµå¼å“åº”...")
    
    try:
        # ä½¿ç”¨æµå¼è¾“å‡º
        response = agent.print_response(
            "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼Œç”¨ä¸­æ–‡å›ç­”ã€‚", 
            stream=True
        )
        
        print("\nâœ… æµå¼å“åº”æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
    
    print("\n" + "=" * 50)
    print("ğŸ¯ æµ‹è¯•è¯´æ˜:")
    print("â€¢ ä½ åº”è¯¥çœ‹åˆ°æ¯ä¸ª chunk çš„è¯¦ç»†ä¿¡æ¯")
    print("â€¢ åŒ…æ‹¬ chunk ç¼–å·ã€å†…å®¹é•¿åº¦ã€ç´¯è®¡é•¿åº¦")
    print("â€¢ ä»¥åŠæ¯ä¸ª chunk çš„å®é™…å†…å®¹")
    print("â€¢ æœ€åä¼šæ˜¾ç¤ºæ•´ä½“ç»Ÿè®¡ä¿¡æ¯")

def test_simple_mode():
    """æµ‹è¯•ç®€æ´æ¨¡å¼"""
    
    print("\nğŸ§ª æµ‹è¯•ç®€æ´è°ƒè¯•æ¨¡å¼")
    print("=" * 50)
    
    # å¯ç”¨ç®€æ´è°ƒè¯•æ¨¡å¼
    enable_stream_debug(verbose=False)
    
    model = VLLM(
        id='Qwen3-Omni-Thinking',
        base_url='http://223.109.239.14:10026/v1/',
        max_tokens=1000,  # è¾ƒçŸ­çš„å“åº”
        temperature=1
    )
    
    agent = Agent(
        model=model,
        tool_choice="none",
        markdown=True,
    )
    
    try:
        # ç®€çŸ­çš„æµ‹è¯•
        response = agent.print_response(
            "è¯´ä¸€å¥è¯", 
            stream=True
        )
        
        print("\nâœ… ç®€æ´æ¨¡å¼æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")

def test_disabled_mode():
    """æµ‹è¯•ç¦ç”¨è°ƒè¯•æ¨¡å¼"""
    
    print("\nğŸ§ª æµ‹è¯•ç¦ç”¨è°ƒè¯•æ¨¡å¼")
    print("=" * 50)
    
    # ç¦ç”¨è°ƒè¯•
    disable_stream_debug()
    
    model = VLLM(
        id='Qwen3-Omni-Thinking',
        base_url='http://223.109.239.14:10026/v1/',
        max_tokens=500,
        temperature=1
    )
    
    agent = Agent(
        model=model,
        tool_choice="none",
        markdown=True,
    )
    
    try:
        # æµ‹è¯•æ— è°ƒè¯•è¾“å‡º
        response = agent.print_response(
            "Hello", 
            stream=True
        )
        
        print("\nâœ… ç¦ç”¨æ¨¡å¼æµ‹è¯•å®Œæˆï¼ˆåº”è¯¥æ²¡æœ‰è°ƒè¯•è¾“å‡ºï¼‰")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸ¯ æµå¼è¾“å‡ºè°ƒè¯•åŠŸèƒ½æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_stream_debug()
    test_simple_mode() 
    test_disabled_mode()
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("â€¢ åœ¨ä½ çš„ä»£ç ä¸­å¯¼å…¥: from stream_debug_utils import enable_stream_debug")
    print("â€¢ å¯ç”¨è°ƒè¯•: enable_stream_debug(verbose=True)  # è¯¦ç»†æ¨¡å¼")
    print("â€¢ å¯ç”¨è°ƒè¯•: enable_stream_debug(verbose=False) # ç®€æ´æ¨¡å¼")
    print("â€¢ ç¦ç”¨è°ƒè¯•: disable_stream_debug()")
    print("â€¢ è°ƒè¯•ä¿¡æ¯ä¼šè‡ªåŠ¨æ˜¾ç¤ºåœ¨æ§åˆ¶å°ä¸­")
